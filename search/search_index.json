{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Alexandre Martinelli</li> <li>Andr\u00e9 Henrique Pacheco Alves</li> <li>Gabriel Cardoso Campos Rodrigues</li> <li>Hugo Coscelli Ferraz</li> <li>Julia Akemi Mullis</li> <li>Theo Camuri Gaspar</li> <li>Grupo Masked Penguins<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p> <p>hsandmann</p>"},{"location":"KNN/main/","title":"KNN","text":""},{"location":"KNN/main/#entrega-individual","title":"Entrega Individual","text":"<ol> <li>Alexandre Martinelli</li> </ol>"},{"location":"KNN/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<ol> <li>Explora\u00e7\u00e3o de dados: Ao selecionar uma base no kaggle referentes a cinco tipos de rem\u00e9dio, rem\u00e9dio A, B, C, X e Y, tem como objetivo prever qual rem\u00e9dio o paciente teria uma resposta melhor. As colunas presentes nesse dataset s\u00e3o Idade, Sexo, Press\u00e3o Arterial, nivel de colesterol, nivel de s\u00f3dio para pot\u00e1ssio no sangue e rem\u00e9dio que seria nossa target. </li> </ol>"},{"location":"KNN/main/#colunas","title":"Colunas","text":"<ol> <li>Age (Idade): Essa coluna temos a idade dos pacientes, com a idade minima presente de 15, idade m\u00e9dia de 44,3 e maxima de 74 sendo do tipo Integer. </li> <li>Sex (Sexo): Essa coluna tem o sexo de cada paciente, divididos em 52% Masculino e 48% feminino, dados do tipo String.</li> <li>Blood Pressure (Press\u00e3o Arterial): Essa coluna tem os niveis de press\u00e3o arterial de cada paciente sendo dividida em 39% HIGH, 29% NORMAL e 32% LOW, dados do tipo String.</li> <li>Cholesterol (nivel de colesterol): Essa coluna tem os niveis de colesterol de cada paciente sendo divididos em 52% HIGH e 49% NORMAL, dados do tipo String.</li> <li>Na_to_K (s\u00f3dio para pot\u00e1ssio): Essa coluna tem os a raz\u00e3o de s\u00f3dio para pot\u00e1ssio no sangue de um paciente, com a minima de 6,27, media de 16,1 e maxima de 38,2, dados do tipo Float/Decimal.</li> <li>Drug (rem\u00e9dio): Essa coluna tem os rem\u00e9dio de melhor resposta para o paciente, dados do tipo String.</li> </ol> Base Age Sex BP Cholesterol Na_to_K Drug 36 M LOW NORMAL 11.424 drugX 16 F HIGH NORMAL 15.516 drugY 18 F NORMAL NORMAL 8.75 drugX 59 F LOW HIGH 10.444 drugC 47 M LOW NORMAL 33.542 drugY 51 M HIGH HIGH 18.295 drugY 18 F HIGH NORMAL 24.276 drugY 28 F NORMAL HIGH 12.879 drugX 42 M HIGH NORMAL 12.766 drugA 66 F NORMAL NORMAL 8.107 drugX"},{"location":"KNN/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Primeiro foi feita uma verifica\u00e7\u00e3o em todas as colunas procurando valores faltantes e substituindo eles pela mediana em valores num\u00e9ricos ou pela moda em vari\u00e1veis categ\u00f3ricas. Como vimos na descri\u00e7\u00e3o das colunas temos tr\u00eas que possuem dados categ\u00f3ricos do tipo String, sendo elas Sex(Sexo), Blood Pressure(Press\u00e3o Arterial) e Cholesterol(nivel de colesterol), para conseguirmos utilizar essas informa\u00e7\u00f5es \u00e9 necessario convertelas em numeros, oque foi feito utilizando a biblioteca scikit-learn que possui a fun\u00e7\u00e3o LabelEncoder(), em seguida aplicamos dois tipos de escalonamento \u00e0s colunas num\u00e9ricas Age e Na_to_K: padroniza\u00e7\u00e3o (z-score) e normaliza\u00e7\u00e3o min-max.</p> ResultPrep CodeStandardizationStandardization code N-Age Sex BP Cholesterol N-Na_to_K Drug 0.4 1 1 1 0.130411 drugX 0 0 0 1 0.291292 drugY 0.04 0 2 1 0.0252801 drugX 0.86 0 1 0 0.0918813 drugC 0.62 1 1 1 1 drugY 0.7 1 0 0 0.40055 drugY 0.04 0 0 1 0.635699 drugY 0.24 0 2 0 0.187615 drugX 0.52 1 0 1 0.183173 drugA 1 0 2 1 0 drugX <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Preprocess the data\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\n# Display the first few rows of the dataset\nprint(df.to_markdown(index=False))\n</code></pre> Age N-Age Z-Age Na_to_K N-Na_to_K Z-Na_to_K 95 36 0.4 -0.117416 11.424 0.130411 -0.526121 15 16 0 -1.23566 15.516 0.291292 -0.0105705 30 18 0.04 -1.12384 8.75 0.0252801 -0.863018 158 59 0.86 1.16857 10.444 0.0918813 -0.649591 128 47 0.62 0.49762 33.542 1 2.26052 115 51 0.7 0.72127 18.295 0.40055 0.339555 69 18 0.04 -1.12384 24.276 0.635699 1.0931 170 28 0.24 -0.564715 12.879 0.187615 -0.342806 174 42 0.52 0.218058 12.766 0.183173 -0.357043 45 66 1 1.55996 8.107 0 -0.944029 <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef standardization(df):\n\n    df['Z-Age'] = df['Age'].apply(lambda x: (x-df['Age'].mean())/df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x-df['Age'].min())/(df['Age'].max()-df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].mean())/df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].min())/(df['Na_to_K'].max()-df['Na_to_K'].min()))\n    df = df[['Age', 'N-Age', 'Z-Age', 'Na_to_K', 'N-Na_to_K', 'Z-Na_to_K']].dropna()\n    print(df.head(10).to_markdown())\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\nstandardization(df)\n</code></pre>"},{"location":"KNN/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O conjunto de dados foi dividido em 70% para treino e 30% para valida\u00e7\u00e3o, garantindo que o modelo fosse treinado em uma parte significativa das observa\u00e7\u00f5es, mas ainda avaliado em dados n\u00e3o vistos. O uso do conjunto de valida\u00e7\u00e3o tem como objetivo detectar e reduzir o risco de overfitting.</p>"},{"location":"KNN/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>Foi utilizada a fun\u00e7\u00e3o <code>permutation_importance()</code> para identificar as features de maior relevancia para o modelo, essa fun\u00e7\u00e3o funciona de seguinte forma: \u00e9 calculada a <code>acur\u00e1cia</code> original do modelo e ap\u00f3s isso ele vai em cada feature embaralhando/permutando os valores no conjunto de teste. Ao finalizar esse processo recalcula a <code>acur\u00e1cia</code> para cada dimens\u00e3o permutada e compara o quanto ela caiu em rela\u00e7\u00e3o a original.</p> Result 70% 30%Code <p>Accuracy: 0.93 Feature Importances (Permutation):  Feature Importance Std N-Na_to_K 0.397222 0.070983 BP 0.332222 0.037990 Cholesterol 0.149444 0.041160 N-Age 0.088889 0.035048 </p>Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support 0 1.000000 0.714286 0.833333 7.000000 1 0.428571 1.000000 0.600000 3.000000 2 1.000000 1.000000 1.000000 6.000000 3 1.000000 1.000000 1.000000 18.000000 4 1.000000 0.923077 0.960000 26.000000 accuracy 0.933333 0.933333 0.933333 0.933333 macro avg 0.885714 0.927473 0.878667 60.000000 weighted avg 0.971429 0.933333 0.943222 60.000000 2025-12-08T17:26:34.209363 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ 2025-12-08T17:26:34.395406 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom itertools import cycle\n\nplt.figure(figsize=(12, 10))\n\ndef standardization(df):\n\n    df['Z-Age'] = df['Age'].apply(lambda x: (x-df['Age'].mean())/df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x-df['Age'].min())/(df['Age'].max()-df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].mean())/df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].min())/(df['Na_to_K'].max()-df['Na_to_K'].min()))\n    features = ['N-Age', 'Sex', 'BP', 'Cholesterol', 'N-Na_to_K', 'Drug']\n    return df[features]\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n    df['Drug'] = label_encoder.fit_transform(df['Drug'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\n\n# Preprocessing\nd = preprocess(df.copy())\nd = standardization(d)\n\n\n# Generate synthetic dataset\nX = d[['N-Age', 'BP', 'Cholesterol', 'N-Na_to_K']]\ny = d['Drug']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train KNN model\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\nr = permutation_importance(\n    knn,                  \n    X_test,               \n    y_test,               \n    n_repeats=30,         \n    random_state=42,\n    scoring='accuracy'    \n)\n\n\nfeature_importance = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': r.importances_mean,\n    'Std': r.importances_std\n})\n\nreport_dict = classification_report(y_test, predictions, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\n\ncm = confusion_matrix(y_test, predictions)\nlabels = knn.classes_\ncm_df = pd.DataFrame(cm, index=labels, columns=labels)\n\n# ordenar e mostrar (HTML igual ao seu exemplo)\nfeature_importance = feature_importance.sort_values(by='Importance', ascending=False)\nprint(\"&lt;br&gt;Feature Importances (Permutation):\")\nprint(feature_importance.to_html(index=False))\n\nprint(\"&lt;h3&gt;Relat\u00f3rio de Classifica\u00e7\u00e3o:&lt;/h3&gt;\")\nprint(report_df.to_html(classes=\"table table-bordered table-striped\", border=0))\n\n# Escalar features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Reduzir para 2 dimens\u00f5es (apenas para visualiza\u00e7\u00e3o)\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Split train/test\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n\n# Treinar KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\n\n\n# Visualize decision boundary\nh = 0.02  # Step size in mesh\nx_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\ny_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.3)\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, style=y, palette=\"deep\", s=100)\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.title(\"KNN Decision Boundary (k=3)\")\n\n# Display the plot\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"KNN/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O modelo KNN (k=3) obteve aproximadamente 0,93 de acur\u00e1cia nos dados de teste, indicando bom desempenho geral. A an\u00e1lise da curva ROC multiclasse (One-vs-Rest) mostra que todas as classes, exceto uma, apresentam \u00e1rea sob a curva (AUC) igual a 1,0, enquanto a \u00faltima classe apresenta AUC de 0,99, sinalizando que o modelo praticamente n\u00e3o erra na maioria das classes, mas pode cometer alguns erros sutis na previs\u00e3o de uma classe espec\u00edfica. Apesar da alta acur\u00e1cia e AUC, \u00e9 recomend\u00e1vel comparar o desempenho nos dados de treino e teste para verificar poss\u00edveis sinais de overfitting. Para aprimorar o modelo, podemos testar diferentes Ks no KNN e usar  t\u00e9cnicas de balanceamento de classes caso haja desbalanceamento.</p>"},{"location":"KNN/main/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"arvore/main/","title":"\u00c1rvore de Decis\u00e3o","text":""},{"location":"arvore/main/#entrega-individual","title":"Entrega Individual","text":"<ol> <li>Alexandre Martinelli</li> </ol>"},{"location":"arvore/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<ol> <li>Explora\u00e7\u00e3o de dados: Ao selecionar uma base no kaggle referentes a cinco tipos de rem\u00e9dio, rem\u00e9dio A, B, C, X e Y, tem como objetivo prever qual rem\u00e9dio o paciente teria uma resposta melhor. As colunas presentes nesse dataset s\u00e3o Idade, Sexo, Press\u00e3o Arterial, nivel de colesterol, nivel de s\u00f3dio para pot\u00e1ssio no sangue e rem\u00e9dio que seria nossa target. </li> </ol>"},{"location":"arvore/main/#colunas","title":"Colunas","text":"<ol> <li>Age (Idade): Essa coluna temos a idade dos pacientes, com a idade minima presente de 15, idade m\u00e9dia de 44,3 e maxima de 74 sendo do tipo Integer. </li> <li>Sex (Sexo): Essa coluna tem o sexo de cada paciente, divididos em 52% Masculino e 48% feminino, dados do tipo String.</li> <li>Blood Pressure (Press\u00e3o Arterial): Essa coluna tem os niveis de press\u00e3o arterial de cada paciente sendo dividida em 39% HIGH, 29% NORMAL e 32% LOW, dados do tipo String.</li> <li>Cholesterol (nivel de colesterol): Essa coluna tem os niveis de colesterol de cada paciente sendo divididos em 52% HIGH e 49% NORMAL, dados do tipo String.</li> <li>Na_to_K (s\u00f3dio para pot\u00e1ssio): Essa coluna tem os a raz\u00e3o de s\u00f3dio para pot\u00e1ssio no sangue de um paciente, com a minima de 6,27, media de 16,1 e maxima de 38,2, dados do tipo Float/Decimal.</li> <li>Drug (rem\u00e9dio): Essa coluna tem os rem\u00e9dio de melhor resposta para o paciente, dados do tipo String.</li> </ol> Base Age Sex BP Cholesterol Na_to_K Drug 36 M LOW NORMAL 11.424 drugX 16 F HIGH NORMAL 15.516 drugY 18 F NORMAL NORMAL 8.75 drugX 59 F LOW HIGH 10.444 drugC 47 M LOW NORMAL 33.542 drugY 51 M HIGH HIGH 18.295 drugY 18 F HIGH NORMAL 24.276 drugY 28 F NORMAL HIGH 12.879 drugX 42 M HIGH NORMAL 12.766 drugA 66 F NORMAL NORMAL 8.107 drugX"},{"location":"arvore/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Primeiro foi feita uma verifica\u00e7\u00e3o em todas as colunas procurando valores faltantes e substituindo eles pela mediana em valores num\u00e9ricos ou pela moda em vari\u00e1veis categ\u00f3ricas. Como vimos na descri\u00e7\u00e3o das colunas temos tr\u00eas que possuem dados categ\u00f3ricos do tipo String, sendo elas Sex(Sexo), Blood Pressure(Press\u00e3o Arterial) e Cholesterol(nivel de colesterol), para conseguirmos utilizar essas informa\u00e7\u00f5es \u00e9 necessario convertelas em numeros, oque foi feito utilizando a biblioteca scikit-learn que possui a fun\u00e7\u00e3o LabelEncoder(), em seguida aplicamos dois tipos de escalonamento \u00e0s colunas num\u00e9ricas Age e Na_to_K: padroniza\u00e7\u00e3o (z-score) e normaliza\u00e7\u00e3o min-max.</p> ResultPrep CodeStandardizationStandardization code N-Age Sex BP Cholesterol N-Na_to_K Drug 0.4 1 1 1 0.130411 drugX 0 0 0 1 0.291292 drugY 0.04 0 2 1 0.0252801 drugX 0.86 0 1 0 0.0918813 drugC 0.62 1 1 1 1 drugY 0.7 1 0 0 0.40055 drugY 0.04 0 0 1 0.635699 drugY 0.24 0 2 0 0.187615 drugX 0.52 1 0 1 0.183173 drugA 1 0 2 1 0 drugX <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Preprocess the data\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\n# Display the first few rows of the dataset\nprint(df.to_markdown(index=False))\n</code></pre> Age N-Age Z-Age Na_to_K N-Na_to_K Z-Na_to_K 95 36 0.4 -0.117416 11.424 0.130411 -0.526121 15 16 0 -1.23566 15.516 0.291292 -0.0105705 30 18 0.04 -1.12384 8.75 0.0252801 -0.863018 158 59 0.86 1.16857 10.444 0.0918813 -0.649591 128 47 0.62 0.49762 33.542 1 2.26052 115 51 0.7 0.72127 18.295 0.40055 0.339555 69 18 0.04 -1.12384 24.276 0.635699 1.0931 170 28 0.24 -0.564715 12.879 0.187615 -0.342806 174 42 0.52 0.218058 12.766 0.183173 -0.357043 45 66 1 1.55996 8.107 0 -0.944029 <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef standardization(df):\n\n    df['Z-Age'] = df['Age'].apply(lambda x: (x-df['Age'].mean())/df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x-df['Age'].min())/(df['Age'].max()-df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].mean())/df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].min())/(df['Na_to_K'].max()-df['Na_to_K'].min()))\n    df = df[['Age', 'N-Age', 'Z-Age', 'Na_to_K', 'N-Na_to_K', 'Z-Na_to_K']].dropna()\n    print(df.head(10).to_markdown())\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\nstandardization(df)\n</code></pre>"},{"location":"arvore/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O conjunto de dados foi dividido em 70% para treino e 30% para valida\u00e7\u00e3o, garantindo que o modelo fosse treinado em uma parte significativa das observa\u00e7\u00f5es, mas ainda avaliado em dados n\u00e3o vistos. O uso do conjunto de valida\u00e7\u00e3o tem como objetivo detectar e reduzir o risco de overfitting.</p>"},{"location":"arvore/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"Result 80% 20%Result 70% 30%Result 60% 40%Result 50% 50%Result 40% 60%Code <p>Accuracy: 1.0 </p>Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support drugA 1.0 1.0 1.0 6.0 drugB 1.0 1.0 1.0 3.0 drugC 1.0 1.0 1.0 5.0 drugX 1.0 1.0 1.0 11.0 drugY 1.0 1.0 1.0 15.0 accuracy 1.0 1.0 1.0 1.0 macro avg 1.0 1.0 1.0 40.0 weighted avg 1.0 1.0 1.0 40.0 Matriz de Confus\u00e3o: drugA drugB drugC drugX drugY drugA 6 0 0 0 0 drugB 0 3 0 0 0 drugC 0 0 5 0 0 drugX 0 0 0 11 0 drugY 0 0 0 0 15 Feature Importances:  Feature Importance 3 N-Na_to_K 0.493261 1 BP 0.265658 0 N-Age 0.135510 2 Cholesterol 0.105571 2025-12-08T17:26:34.694156 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p></p> <p>Accuracy: 1.0 </p>Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support drugA 1.0 1.0 1.0 7.0 drugB 1.0 1.0 1.0 3.0 drugC 1.0 1.0 1.0 6.0 drugX 1.0 1.0 1.0 18.0 drugY 1.0 1.0 1.0 26.0 accuracy 1.0 1.0 1.0 1.0 macro avg 1.0 1.0 1.0 60.0 weighted avg 1.0 1.0 1.0 60.0 Matriz de Confus\u00e3o: drugA drugB drugC drugX drugY drugA 7 0 0 0 0 drugB 0 3 0 0 0 drugC 0 0 6 0 0 drugX 0 0 0 18 0 drugY 0 0 0 0 26 Feature Importances:  Feature Importance 3 N-Na_to_K 0.476110 1 BP 0.267512 0 N-Age 0.148169 2 Cholesterol 0.108209 2025-12-08T17:26:34.928290 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p></p> <p>Accuracy: 1.0 </p>Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support drugA 1.0 1.0 1.0 10.0 drugB 1.0 1.0 1.0 6.0 drugC 1.0 1.0 1.0 6.0 drugX 1.0 1.0 1.0 25.0 drugY 1.0 1.0 1.0 33.0 accuracy 1.0 1.0 1.0 1.0 macro avg 1.0 1.0 1.0 80.0 weighted avg 1.0 1.0 1.0 80.0 Matriz de Confus\u00e3o: drugA drugB drugC drugX drugY drugA 10 0 0 0 0 drugB 0 6 0 0 0 drugC 0 0 6 0 0 drugX 0 0 0 25 0 drugY 0 0 0 0 33 Feature Importances:  Feature Importance 3 N-Na_to_K 0.481166 1 BP 0.258655 0 N-Age 0.138054 2 Cholesterol 0.122125 2025-12-08T17:26:35.160659 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p></p> <p>Accuracy: 1.0 </p>Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support drugA 1.0 1.0 1.0 16.0 drugB 1.0 1.0 1.0 8.0 drugC 1.0 1.0 1.0 7.0 drugX 1.0 1.0 1.0 27.0 drugY 1.0 1.0 1.0 42.0 accuracy 1.0 1.0 1.0 1.0 macro avg 1.0 1.0 1.0 100.0 weighted avg 1.0 1.0 1.0 100.0 Matriz de Confus\u00e3o: drugA drugB drugC drugX drugY drugA 16 0 0 0 0 drugB 0 8 0 0 0 drugC 0 0 7 0 0 drugX 0 0 0 27 0 drugY 0 0 0 0 42 Feature Importances:  Feature Importance 3 N-Na_to_K 0.507161 1 BP 0.246185 2 Cholesterol 0.134811 0 N-Age 0.111843 2025-12-08T17:26:35.463578 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p></p> <p>Accuracy: 0.9916666666666667 </p>Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support drugA 1.000000 1.000000 1.000000 17.000000 drugB 1.000000 1.000000 1.000000 11.000000 drugC 1.000000 1.000000 1.000000 8.000000 drugX 1.000000 0.970588 0.985075 34.000000 drugY 0.980392 1.000000 0.990099 50.000000 accuracy 0.991667 0.991667 0.991667 0.991667 macro avg 0.996078 0.994118 0.995035 120.000000 weighted avg 0.991830 0.991667 0.991646 120.000000 Matriz de Confus\u00e3o: drugA drugB drugC drugX drugY drugA 17 0 0 0 0 drugB 0 11 0 0 0 drugC 0 0 8 0 0 drugX 0 0 0 33 1 drugY 0 0 0 0 50 Feature Importances:  Feature Importance 3 N-Na_to_K 0.512857 1 BP 0.265714 2 Cholesterol 0.117384 0 N-Age 0.104045 2025-12-08T17:26:35.697752 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p></p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\ndef standardization(df):\n\n    df['Z-Age'] = df['Age'].apply(lambda x: (x-df['Age'].mean())/df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x-df['Age'].min())/(df['Age'].max()-df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].mean())/df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].min())/(df['Na_to_K'].max()-df['Na_to_K'].min()))\n    features = ['N-Age', 'Sex', 'BP', 'Cholesterol', 'N-Na_to_K', 'Drug']\n    return df[features]\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\n\n# Preprocessing\nd = preprocess(df.copy())\nd = standardization(d)\n\nplt.figure(figsize=(12, 10))\n\n# Carregar o conjunto de dados\nx = d[['N-Age', 'BP', 'Cholesterol', 'N-Na_to_K']]\ny = d['Drug']\n\n# Dividir os dados em conjuntos de treinamento e teste\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6, random_state=42)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\ny_pred = classifier.predict(x_test)\n\ncm = confusion_matrix(y_test, y_pred)\nlabels = classifier.classes_\ncm_df = pd.DataFrame(cm, index=labels, columns=labels)\n\nreport_dict = classification_report(y_test, y_pred, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\n\n# Avaliar o modelo\naccuracy = classifier.score(x_test, y_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n\nprint(\"&lt;h3&gt;Relat\u00f3rio de Classifica\u00e7\u00e3o:&lt;/h3&gt;\")\nprint(report_df.to_html(classes=\"table table-bordered table-striped\", border=0))\n\nprint(\"&lt;h3&gt;Matriz de Confus\u00e3o:&lt;/h3&gt;\")\nprint(cm_df.to_html(classes=\"table table-bordered table-striped\", border=0))\n\n# Optional: Print feature importances\nfeature_importance = pd.DataFrame({\n    'Feature': ['N-Age', 'BP', 'Cholesterol', 'N-Na_to_K'],\n    'Importance': classifier.feature_importances_\n})\nprint(\"&lt;br&gt;Feature Importances:\")\nprint(feature_importance.sort_values(by='Importance', ascending=False).to_html())\n\ntree.plot_tree(classifier)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"arvore/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Como vimos na se\u00e7\u00e3o de treinamento, a base selecionada para o treinamento da \u00e1rvore n\u00e3o \u00e9 ideal, apresentando 100% de accuracy, precision, recall e F1-score em diferentes divis\u00f5es dos dados (80%/20%, 70%/30%, 60%/40%, 50%/50%),  apresentando pouca varia\u00e7\u00e3o apenas quando a divis\u00e3o chega em 40% treino e 60% teste. Isso indica que a \u00e1rvore de decis\u00e3o provavelmente est\u00e1 sofrendo de overfitting, ou seja, aprendeu particularidades espec\u00edficas da base em vez de padr\u00f5es gerais. Assim, embora apresente resultados excelentes nos testes, o modelo pode n\u00e3o generalizar bem para dados realmente novos. Uma poss\u00edvel melhoria seria aumentar a quantidade de dados para reduzir o overfitting.</p>"},{"location":"arvore/main/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"kmeans/main%202/","title":"Main 2","text":""},{"location":"kmeans/main%202/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"kmeans/main%202/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"kmeans/main%20copy/","title":"Main copy","text":""},{"location":"kmeans/main%20copy/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"kmeans/main%20copy/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"kmeans/main%20copy/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"kmeans/main%20copy/#tarefa-2","title":"Tarefa 2","text":""},{"location":"kmeans/main%20copy/#app","title":"App","text":""},{"location":"kmeans/main%20copy/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"kmeans/main%20copy/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"kmeans/main%20copy/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"kmeans/main%20copy/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"kmeans/main%20copy/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"kmeans/main/","title":"K-Means","text":""},{"location":"kmeans/main/#entrega-individual","title":"Entrega Individual","text":"<ol> <li>Alexandre Martinelli</li> </ol>"},{"location":"kmeans/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<ol> <li>Explora\u00e7\u00e3o de dados: Ao selecionar uma base no kaggle referentes a cinco tipos de rem\u00e9dio, rem\u00e9dio A, B, C, X e Y, tem como objetivo prever qual rem\u00e9dio o paciente teria uma resposta melhor. As colunas presentes nesse dataset s\u00e3o Idade, Sexo, Press\u00e3o Arterial, nivel de colesterol, nivel de s\u00f3dio para pot\u00e1ssio no sangue e rem\u00e9dio que seria nossa target. </li> </ol>"},{"location":"kmeans/main/#colunas","title":"Colunas","text":"<ol> <li>Age (Idade): Essa coluna temos a idade dos pacientes, com a idade minima presente de 15, idade m\u00e9dia de 44,3 e maxima de 74 sendo do tipo Integer. </li> <li>Sex (Sexo): Essa coluna tem o sexo de cada paciente, divididos em 52% Masculino e 48% feminino, dados do tipo String.</li> <li>Blood Pressure (Press\u00e3o Arterial): Essa coluna tem os niveis de press\u00e3o arterial de cada paciente sendo dividida em 39% HIGH, 29% NORMAL e 32% LOW, dados do tipo String.</li> <li>Cholesterol (nivel de colesterol): Essa coluna tem os niveis de colesterol de cada paciente sendo divididos em 52% HIGH e 49% NORMAL, dados do tipo String.</li> <li>Na_to_K (s\u00f3dio para pot\u00e1ssio): Essa coluna tem os a raz\u00e3o de s\u00f3dio para pot\u00e1ssio no sangue de um paciente, com a minima de 6,27, media de 16,1 e maxima de 38,2, dados do tipo Float/Decimal.</li> <li>Drug (rem\u00e9dio): Essa coluna tem os rem\u00e9dio de melhor resposta para o paciente, dados do tipo String.</li> </ol> Base Age Sex BP Cholesterol Na_to_K Drug 36 M LOW NORMAL 11.424 drugX 16 F HIGH NORMAL 15.516 drugY 18 F NORMAL NORMAL 8.75 drugX 59 F LOW HIGH 10.444 drugC 47 M LOW NORMAL 33.542 drugY 51 M HIGH HIGH 18.295 drugY 18 F HIGH NORMAL 24.276 drugY 28 F NORMAL HIGH 12.879 drugX 42 M HIGH NORMAL 12.766 drugA 66 F NORMAL NORMAL 8.107 drugX"},{"location":"kmeans/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Primeiro foi feita uma verifica\u00e7\u00e3o em todas as colunas procurando valores faltantes e substituindo eles pela mediana em valores num\u00e9ricos ou pela moda em vari\u00e1veis categ\u00f3ricas. Como vimos na descri\u00e7\u00e3o das colunas temos tr\u00eas que possuem dados categ\u00f3ricos do tipo String, sendo elas Sex(Sexo), Blood Pressure(Press\u00e3o Arterial) e Cholesterol(nivel de colesterol), para conseguirmos utilizar essas informa\u00e7\u00f5es \u00e9 necessario convertelas em numeros, oque foi feito utilizando a biblioteca scikit-learn que possui a fun\u00e7\u00e3o LabelEncoder(), em seguida aplicamos dois tipos de escalonamento \u00e0s colunas num\u00e9ricas Age e Na_to_K: padroniza\u00e7\u00e3o (z-score) e normaliza\u00e7\u00e3o min-max.</p> ResultPrep CodeStandardizationStandardization code N-Age Sex BP Cholesterol N-Na_to_K Drug 0.4 1 1 1 0.130411 drugX 0 0 0 1 0.291292 drugY 0.04 0 2 1 0.0252801 drugX 0.86 0 1 0 0.0918813 drugC 0.62 1 1 1 1 drugY 0.7 1 0 0 0.40055 drugY 0.04 0 0 1 0.635699 drugY 0.24 0 2 0 0.187615 drugX 0.52 1 0 1 0.183173 drugA 1 0 2 1 0 drugX <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Preprocess the data\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\n# Display the first few rows of the dataset\nprint(df.to_markdown(index=False))\n</code></pre> Age N-Age Z-Age Na_to_K N-Na_to_K Z-Na_to_K 95 36 0.4 -0.117416 11.424 0.130411 -0.526121 15 16 0 -1.23566 15.516 0.291292 -0.0105705 30 18 0.04 -1.12384 8.75 0.0252801 -0.863018 158 59 0.86 1.16857 10.444 0.0918813 -0.649591 128 47 0.62 0.49762 33.542 1 2.26052 115 51 0.7 0.72127 18.295 0.40055 0.339555 69 18 0.04 -1.12384 24.276 0.635699 1.0931 170 28 0.24 -0.564715 12.879 0.187615 -0.342806 174 42 0.52 0.218058 12.766 0.183173 -0.357043 45 66 1 1.55996 8.107 0 -0.944029 <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef standardization(df):\n\n    df['Z-Age'] = df['Age'].apply(lambda x: (x-df['Age'].mean())/df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x-df['Age'].min())/(df['Age'].max()-df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].mean())/df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].min())/(df['Na_to_K'].max()-df['Na_to_K'].min()))\n    df = df[['Age', 'N-Age', 'Z-Age', 'Na_to_K', 'N-Na_to_K', 'Z-Na_to_K']].dropna()\n    print(df.head(10).to_markdown())\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\nstandardization(df)\n</code></pre>"},{"location":"kmeans/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O conjunto de dados foi dividido em 70% para treino e 30% para valida\u00e7\u00e3o, garantindo que o modelo fosse treinado em uma parte significativa das observa\u00e7\u00f5es, mas ainda avaliado em dados n\u00e3o vistos. O uso do conjunto de valida\u00e7\u00e3o tem como objetivo detectar e reduzir o risco de overfitting.</p>"},{"location":"kmeans/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"Result 70% 30%Code <p>Acur\u00e1cia: 0.56% Matriz de Confus\u00e3o:  Classe Pred 0 Classe Pred 1 Classe Pred 2 Classe Pred 3 Classe Pred 4 Classe Real 0 0 0 0 0 17 Classe Real 1 0 0 0 0 13 Classe Real 2 0 0 0 0 11 Classe Real 3 0 0 0 43 0 Classe Real 4 0 0 0 30 46 2025-12-08T17:26:36.073952 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nimport pandas as pd\nfrom scipy.stats import mode\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.decomposition import PCA  \n\n\nplt.figure(figsize=(12, 10))\n\ndef standardization(df):\n    df['Z-Age'] = df['Age'].apply(lambda x: (x - df['Age'].mean()) / df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x - df['Age'].min()) / (df['Age'].max() - df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x - df['Na_to_K'].mean()) / df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x - df['Na_to_K'].min()) / (df['Na_to_K'].max() - df['Na_to_K'].min()))\n    features = ['N-Age', 'Sex', 'BP', 'Cholesterol', 'N-Na_to_K', 'Drug']\n    return df[features]\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n    # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n    df['Drug'] = label_encoder.fit_transform(df['Drug'])\n\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\nlabel_encoder = LabelEncoder()\n# Load dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\n\n# Preprocessing\nd = preprocess(df.copy())\nd = standardization(d)\n\nX = d[['N-Age', 'BP', 'Cholesterol', 'N-Na_to_K']]\ny = d['Drug']\n\n#Separar em teste e valida\u00e7\u00e3o\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reduzir para 2 dimens\u00f5es com PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_train)\n\n# Treinar KMeans\nkmeans = KMeans(n_clusters=5, init=\"k-means++\", max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Mapear clusters para classes reais por voto majorit\u00e1rio\ncluster_map = {}\nfor c in np.unique(labels):\n    mask = labels == c\n    majority_class = mode(y_train[mask], keepdims=False)[0]\n    cluster_map[c] = majority_class\n\n# Reatribuir clusters como classes previstas\ny_pred = np.array([cluster_map[c] for c in labels])\n\n# Calcular acur\u00e1cia e matriz de confus\u00e3o\nacc = accuracy_score(y_train, y_pred)\ncm = confusion_matrix(y_train, y_pred)\n\ncm_df = pd.DataFrame(\n    cm,\n    index=[f\"Classe Real {cls}\" for cls in np.unique(y_train)],\n    columns=[f\"Classe Pred {cls}\" for cls in np.unique(y_train)]\n)\n\nprint(f\"Acur\u00e1cia: {acc:.2f}%\")\nprint(\"&lt;br&gt;Matriz de Confus\u00e3o:\")\nprint(cm_df.to_html())\n\n# Tamb\u00e9m projetar os centr\u00f3ides no PCA\ncentroids_pca = kmeans.cluster_centers_\n\n\n# Plot results\nplt.figure(figsize=(10, 8))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], \n           c='red', marker='*', s=200, label='Centroids')\nplt.title('K-Means Clustering (PCA 2D)')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.legend()\n\n# Save plot to buffer\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"kmeans/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O K-Means, mesmo ap\u00f3s redu\u00e7\u00e3o com PCA, n\u00e3o conseguiu reproduzir bem as cinco classes do conjunto de dados. A matriz de confus\u00e3o mostra que os clusters formados concentram-se principalmente em duas classes, indicando que o algoritmo n\u00e3o separou adequadamente todas as categorias. Assim, a acur\u00e1cia obtida reflete apenas a sobreposi\u00e7\u00e3o entre clusters e classes reais. Uma poss\u00edvel melhoria seria aumentar a quantidade de dados.</p>"},{"location":"kmeans/main/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"pagerank/main/","title":"Page Rank","text":""},{"location":"pagerank/main/#entrega-individual","title":"Entrega Individual","text":"<ol> <li>Alexandre Martinelli</li> </ol>"},{"location":"pagerank/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>O objetivo deste exerc\u00edcio \u00e9 implementar e analisar o algoritmo PageRank aplicado a um grafo dirigido de cita\u00e7\u00f5es acad\u00eamicas. O PageRank, originalmente desenvolvido para ranquear p\u00e1ginas web, \u00e9 aqui utilizado para identificar os artigos (papers) mais influentes dentro da comunidade de F\u00edsica de Alta Energia.</p>"},{"location":"pagerank/main/#descricao-do-dataset","title":"Descri\u00e7\u00e3o do Dataset","text":"<p>Para este estudo, foi selecionado o dataset cit-HepTh (High Energy Physics - Theory), disponibilizado pelo reposit\u00f3rio SNAP (Stanford Network Analysis Platform).</p> <ul> <li>Dominio: F\u00edsica de Alta Energia (Teoria).</li> <li>Tipo de Grafo: Dirigido (Directed).</li> <li>N\u00f3s: Representam artigos cient\u00edficos (papers) submetidos ao arXiv.</li> <li>Arestas: Representam cita\u00e7\u00f5es. Uma aresta \\(u \\to v\\) indica que o artigo \\(u\\) cita o artigo \\(v\\).</li> <li>Per\u00edodo: Abrange papers de Jan/1993 a Abr/2003.</li> </ul> <p>Estat\u00edsticas da Base: * Total de N\u00f3s: 27.770 * Total de Arestas: 352.807 * Interpreta\u00e7\u00e3o: Neste contexto, um \"alto PageRank\" indica um paper fundamental ou seminal, que recebeu cita\u00e7\u00f5es de outros papers tamb\u00e9m importantes.</p>"},{"location":"pagerank/main/#metodologia","title":"Metodologia","text":"<p>A implementa\u00e7\u00e3o foi realizada em duas etapas: 1.  Implementa\u00e7\u00e3o Manual: O algoritmo foi desenvolvido do zero utilizando a f\u00f3rmula iterativa do m\u00e9todo da pot\u00eancia, com fator de amortecimento \\(d=0.85\\) e crit\u00e9rio de converg\u00eancia \\(\\epsilon &lt; 10^{-4}\\). 2.  Valida\u00e7\u00e3o: Os resultados foram comparados com a implementa\u00e7\u00e3o da biblioteca <code>NetworkX</code>.</p>"},{"location":"pagerank/main/#visualizacao-da-rede","title":"Visualiza\u00e7\u00e3o da Rede","text":"<p>A imagem abaixo apresenta um subgrafo contendo os 50 artigos (n\u00f3s) com maior n\u00famero de conex\u00f5es (cita\u00e7\u00f5es feitas + recebidas). O tamanho dos n\u00f3s \u00e9 proporcional ao seu grau.</p> <p></p> <p>Figura 1: Visualiza\u00e7\u00e3o gerada via NetworkX destacando os hubs centrais da rede Cit-HepTh.</p>"},{"location":"pagerank/main/#resultados-e-discussao","title":"Resultados e Discuss\u00e3o","text":"<p>Nesta se\u00e7\u00e3o, apresentamos os resultados obtidos pela implementa\u00e7\u00e3o manual do algoritmo PageRank e os comparamos com a implementa\u00e7\u00e3o de refer\u00eancia da biblioteca <code>NetworkX</code>. A an\u00e1lise foi realizada sobre o dataset Cit-HepTh (Cita\u00e7\u00f5es de F\u00edsica de Alta Energia).</p>"},{"location":"pagerank/main/#cenario-padrao-d-085","title":"Cen\u00e1rio Padr\u00e3o (d = 0.85)","text":"<p>O fator de amortecimento d = 0.85 \u00e9 o padr\u00e3o da ind\u00fastria e modela o comportamento de um \"caminhante aleat\u00f3rio\" (random walker). Isso significa que existe 85% de probabilidade de o caminhante seguir um link de cita\u00e7\u00e3o existente e 15% de probabilidade de ele reiniciar o processo em um artigo aleat\u00f3rio da base.</p> Result d(0.85)Result d(0.5)Result d(0.99) <p>Converg\u00eancia em 26 itera\u00e7\u00f5es.</p> Rank (NX) Paper ID In-Degree PR Manual PR NetworkX Dif 1 9711200 2414 0.003368 0.003999 6.31e-04 2 9407087 1299 0.006086 0.003280 2.81e-03 3 9802150 1775 0.002230 0.002769 5.39e-04 4 9802109 1641 0.002045 0.002385 3.39e-04 5 9906064 1032 0.001742 0.002359 6.18e-04 6 9908142 1144 0.001397 0.002231 8.34e-04 7 9408099 1006 0.003125 0.002152 9.74e-04 8 9610043 1199 0.002666 0.002145 5.21e-04 9 9510017 1155 0.004211 0.001868 2.34e-03 10 9503124 1114 0.004471 0.001753 2.72e-03 <p>Converg\u00eancia em 26 itera\u00e7\u00f5es.</p> Rank (NX) Paper ID In-Degree PR Manual PR NetworkX Dif 1 9711200 2414 0.003368 0.002367 1.00e-03 2 9407087 1299 0.006086 0.001944 4.14e-03 3 9802150 1775 0.002230 0.001644 5.86e-04 4 9802109 1641 0.002045 0.001418 6.28e-04 5 9906064 1032 0.001742 0.001403 3.39e-04 6 9908142 1144 0.001397 0.001327 6.98e-05 7 9408099 1006 0.003125 0.001280 1.85e-03 8 9610043 1199 0.002666 0.001277 1.39e-03 9 9510017 1155 0.004211 0.001114 3.10e-03 10 9503124 1114 0.004471 0.001046 3.43e-03 <p>Converg\u00eancia em 26 itera\u00e7\u00f5es.</p> Rank (NX) Paper ID In-Degree PR Manual PR NetworkX Dif 1 9711200 2414 0.003368 0.004652 1.28e-03 2 9407087 1299 0.006086 0.003814 2.27e-03 3 9802150 1775 0.002230 0.003219 9.89e-04 4 9802109 1641 0.002045 0.002771 7.26e-04 5 9906064 1032 0.001742 0.002742 1.00e-03 6 9908142 1144 0.001397 0.002592 1.20e-03 7 9408099 1006 0.003125 0.002500 6.25e-04 8 9610043 1199 0.002666 0.002492 1.74e-04 9 9510017 1155 0.004211 0.002170 2.04e-03 10 9503124 1114 0.004471 0.002035 2.44e-03 <p>An\u00e1lise dos L\u00edderes: O algoritmo identificou corretamente os trabalhos seminais da \u00e1rea. O paper #1 (ID 9711200) refere-se ao artigo \"The Large N Limit of Superconformal Field Theories and Supergravity\" de Juan Maldacena. Este \u00e9 historicamente o trabalho mais citado em F\u00edsica de Altas Energias, estabelecendo a correspond\u00eancia AdS/CFT. O PageRank confirma sua import\u00e2ncia estrutural na rede, superando outros artigos que, embora tenham muitas cita\u00e7\u00f5es, n\u00e3o possuem a mesma centralidade de influ\u00eancia.</p> <p>Valida\u00e7\u00e3o da Implementa\u00e7\u00e3o: A implementa\u00e7\u00e3o manual convergiu em 26 itera\u00e7\u00f5es. Observa-se que ambos os algoritmos identificaram o mesmo grupo de \"elite\" (Top 10). As diverg\u00eancias num\u00e9ricas na coluna \"Diferen\u00e7a\" ocorrem devido \u00e0s diferentes estrat\u00e9gias de tratamento matem\u00e1tico dos dangling nodes (n\u00f3s sem sa\u00edda): enquanto o <code>NetworkX</code> redistribui essa massa via otimiza\u00e7\u00e3o matricial, a implementa\u00e7\u00e3o manual realiza uma redistribui\u00e7\u00e3o iterativa.</p>"},{"location":"pagerank/main/#analise-de-sensibilidade-variacao-do-fator-d","title":"An\u00e1lise de Sensibilidade: Varia\u00e7\u00e3o do Fator d","text":"<p>Para compreender o impacto do fator de amortecimento na import\u00e2ncia dos n\u00f3s, variamos o par\u00e2metro para um valor baixo (0.5) e um extremo (0.99).</p> <p>Tabela: Comparativo dos Top Papers sob diferentes fatores d</p> Paper ID PR (d=0.5) PR (d=0.85) PR (d=0.99) Tend\u00eancia 9711200 0.002367 0.003999 0.004652 \u2b06 Crescente 9407087 0.001944 0.003280 0.003814 \u2b06 Crescente 9802150 0.001644 0.002769 0.003219 \u2b06 Crescente <p>Discuss\u00e3o dos Cen\u00e1rios:</p> <ol> <li> <p>Cen\u00e1rio de Alto Teleporte (d = 0.5):</p> <ul> <li>Neste cen\u00e1rio, o caminhante aleat\u00f3rio tem 50% de chance de abandonar a navega\u00e7\u00e3o atual e pular para qualquer outro n\u00f3.</li> <li>Resultado: O PageRank do l\u00edder caiu de ~0.0040 para 0.0023.</li> <li>Interpreta\u00e7\u00e3o: A rede se torna mais \"democr\u00e1tica\". A influ\u00eancia dos grandes hubs \u00e9 dilu\u00edda, pois a probabilidade de chegar a eles atrav\u00e9s de caminhos longos diminui, j\u00e1 que o processo \u00e9 interrompido com mais frequ\u00eancia.</li> </ul> </li> <li> <p>Cen\u00e1rio de Estrutura Pura (d = 0.99):</p> <ul> <li>Neste cen\u00e1rio, o caminhante quase nunca para (apenas 1% de chance de teleporte), seguindo as cita\u00e7\u00f5es indefinidamente.</li> <li>Resultado: O PageRank do l\u00edder subiu para 0.0046.</li> <li>Interpreta\u00e7\u00e3o: Ocorre o efeito \"Winner-takes-all\" (o vencedor leva tudo). A estrutura de conex\u00f5es domina completamente o ranking, concentrando ainda mais prest\u00edgio nos n\u00f3s centrais e ampliando a desigualdade entre os papers mais citados e os perif\u00e9ricos.</li> </ul> </li> </ol>"},{"location":"pagerank/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Este exerc\u00edcio permitiu a implementa\u00e7\u00e3o bem-sucedida do algoritmo PageRank, validada atrav\u00e9s da compara\u00e7\u00e3o com a biblioteca <code>NetworkX</code>.</p> <p>Conclui-se que: 1.  Efic\u00e1cia: O algoritmo manual foi capaz de identificar corretamente os artigos seminais da f\u00edsica te\u00f3rica, coincidindo com o ranking da biblioteca padr\u00e3o. 2.  Qualidade vs Quantidade: O PageRank provou ser uma m\u00e9trica mais robusta que o simples Grau de Entrada (n\u00famero de cita\u00e7\u00f5es), pois pondera a qualidade das cita\u00e7\u00f5es recebidas. 3.  Robustez: A an\u00e1lise de sensibilidade demonstrou que, embora os valores absolutos mudem conforme o fator de amortecimento d, o conjunto dos principais artigos mant\u00e9m-se est\u00e1vel, indicando que sua relev\u00e2ncia \u00e9 uma propriedade intr\u00ednseca da estrutura da comunidade cient\u00edfica analisada.</p>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"pyspark/main/","title":"PySpark","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"randomforest/main/","title":"Random Forest","text":""},{"location":"randomforest/main/#entrega-individual","title":"Entrega Individual","text":"<ol> <li>Alexandre Martinelli</li> </ol>"},{"location":"randomforest/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<ol> <li>Explora\u00e7\u00e3o de dados: Ao selecionar uma base no kaggle referentes a cinco tipos de rem\u00e9dio, rem\u00e9dio A, B, C, X e Y, tem como objetivo prever qual rem\u00e9dio o paciente teria uma resposta melhor. As colunas presentes nesse dataset s\u00e3o Idade, Sexo, Press\u00e3o Arterial, nivel de colesterol, nivel de s\u00f3dio para pot\u00e1ssio no sangue e rem\u00e9dio que seria nossa target. </li> </ol>"},{"location":"randomforest/main/#colunas","title":"Colunas","text":"<ol> <li>Age (Idade): Essa coluna temos a idade dos pacientes, com a idade minima presente de 15, idade m\u00e9dia de 44,3 e maxima de 74 sendo do tipo Integer. </li> <li>Sex (Sexo): Essa coluna tem o sexo de cada paciente, divididos em 52% Masculino e 48% feminino, dados do tipo String.</li> <li>Blood Pressure (Press\u00e3o Arterial): Essa coluna tem os niveis de press\u00e3o arterial de cada paciente sendo dividida em 39% HIGH, 29% NORMAL e 32% LOW, dados do tipo String.</li> <li>Cholesterol (nivel de colesterol): Essa coluna tem os niveis de colesterol de cada paciente sendo divididos em 52% HIGH e 49% NORMAL, dados do tipo String.</li> <li>Na_to_K (s\u00f3dio para pot\u00e1ssio): Essa coluna tem os a raz\u00e3o de s\u00f3dio para pot\u00e1ssio no sangue de um paciente, com a minima de 6,27, media de 16,1 e maxima de 38,2, dados do tipo Float/Decimal.</li> <li>Drug (rem\u00e9dio): Essa coluna tem os rem\u00e9dio de melhor resposta para o paciente, dados do tipo String.</li> </ol> Base Age Sex BP Cholesterol Na_to_K Drug 36 M LOW NORMAL 11.424 drugX 16 F HIGH NORMAL 15.516 drugY 18 F NORMAL NORMAL 8.75 drugX 59 F LOW HIGH 10.444 drugC 47 M LOW NORMAL 33.542 drugY 51 M HIGH HIGH 18.295 drugY 18 F HIGH NORMAL 24.276 drugY 28 F NORMAL HIGH 12.879 drugX 42 M HIGH NORMAL 12.766 drugA 66 F NORMAL NORMAL 8.107 drugX"},{"location":"randomforest/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Primeiro foi feita uma verifica\u00e7\u00e3o em todas as colunas procurando valores faltantes e substituindo eles pela mediana em valores num\u00e9ricos ou pela moda em vari\u00e1veis categ\u00f3ricas. Como vimos na descri\u00e7\u00e3o das colunas temos tr\u00eas que possuem dados categ\u00f3ricos do tipo String, sendo elas Sex(Sexo), Blood Pressure(Press\u00e3o Arterial) e Cholesterol(nivel de colesterol), para conseguirmos utilizar essas informa\u00e7\u00f5es \u00e9 necessario convertelas em numeros, oque foi feito utilizando a biblioteca scikit-learn que possui a fun\u00e7\u00e3o LabelEncoder(), em seguida aplicamos dois tipos de escalonamento \u00e0s colunas num\u00e9ricas Age e Na_to_K: padroniza\u00e7\u00e3o (z-score) e normaliza\u00e7\u00e3o min-max.</p> ResultPrep CodeStandardizationStandardization code N-Age Sex BP Cholesterol N-Na_to_K Drug 0.4 1 1 1 0.130411 drugX 0 0 0 1 0.291292 drugY 0.04 0 2 1 0.0252801 drugX 0.86 0 1 0 0.0918813 drugC 0.62 1 1 1 1 drugY 0.7 1 0 0 0.40055 drugY 0.04 0 0 1 0.635699 drugY 0.24 0 2 0 0.187615 drugX 0.52 1 0 1 0.183173 drugA 1 0 2 1 0 drugX <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Preprocess the data\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\n# Display the first few rows of the dataset\nprint(df.to_markdown(index=False))\n</code></pre> Age N-Age Z-Age Na_to_K N-Na_to_K Z-Na_to_K 95 36 0.4 -0.117416 11.424 0.130411 -0.526121 15 16 0 -1.23566 15.516 0.291292 -0.0105705 30 18 0.04 -1.12384 8.75 0.0252801 -0.863018 158 59 0.86 1.16857 10.444 0.0918813 -0.649591 128 47 0.62 0.49762 33.542 1 2.26052 115 51 0.7 0.72127 18.295 0.40055 0.339555 69 18 0.04 -1.12384 24.276 0.635699 1.0931 170 28 0.24 -0.564715 12.879 0.187615 -0.342806 174 42 0.52 0.218058 12.766 0.183173 -0.357043 45 66 1 1.55996 8.107 0 -0.944029 <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef standardization(df):\n\n    df['Z-Age'] = df['Age'].apply(lambda x: (x-df['Age'].mean())/df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x-df['Age'].min())/(df['Age'].max()-df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].mean())/df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].min())/(df['Na_to_K'].max()-df['Na_to_K'].min()))\n    df = df[['Age', 'N-Age', 'Z-Age', 'Na_to_K', 'N-Na_to_K', 'Z-Na_to_K']].dropna()\n    print(df.head(10).to_markdown())\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\nstandardization(df)\n</code></pre>"},{"location":"randomforest/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O conjunto de dados foi dividido em 70% para treino e 30% para valida\u00e7\u00e3o, garantindo que o modelo fosse treinado em uma parte significativa das observa\u00e7\u00f5es, mas ainda avaliado em dados n\u00e3o vistos. O uso do conjunto de valida\u00e7\u00e3o tem como objetivo detectar e reduzir o risco de overfitting.</p>"},{"location":"randomforest/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"Result 70% 30% <p>Accuracy: 1.0 </p>Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support drugA 1.0 1.0 1.0 7.0 drugB 1.0 1.0 1.0 3.0 drugC 1.0 1.0 1.0 6.0 drugX 1.0 1.0 1.0 18.0 drugY 1.0 1.0 1.0 26.0 accuracy 1.0 1.0 1.0 1.0 macro avg 1.0 1.0 1.0 60.0 weighted avg 1.0 1.0 1.0 60.0 Matriz de Confus\u00e3o: drugA drugB drugC drugX drugY drugA 7 0 0 0 0 drugB 0 3 0 0 0 drugC 0 0 6 0 0 drugX 0 0 0 18 0 drugY 0 0 0 0 26 Feature Importances:  Feature Importance 3 N-Na_to_K 0.559355 1 BP 0.257754 0 N-Age 0.132266 2 Cholesterol 0.050625 <p></p>"},{"location":"randomforest/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>No experimento, a Random Forest foi treinada com divis\u00e3o 70% treino / 30% valida\u00e7\u00e3o do dataset de f\u00e1rmacos (drugA\u2013drugY), conforme definido no plano de execu\u00e7\u00e3o e script de treinamento. Nos resultados, o modelo alcan\u00e7ou accuracy = 1,0, com precision recall e F1-score iguais a 1,0 para todas as classes (supports: drugA = 7, drugB = 3, drugC = 6, drugX = 18, drugY = 26), e macro/weighted avg = 1,0, a matriz de confus\u00e3o n\u00e3o registrou erros de classifica\u00e7\u00e3o. As import\u00e2ncias de atributos estimadas pela floresta indicaram maior influ\u00eancia de Na_to_K (~0,559), seguida por BP (~0,258), Age (~0,132) e Cholesterol (~0,051), coerente com a capacidade do algoritmo de ponderar vari\u00e1veis por ganho de impureza.</p>"},{"location":"randomforest/main/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"svm/main/","title":"SVM","text":""},{"location":"svm/main/#entrega-individual","title":"Entrega Individual","text":"<ol> <li>Alexandre Martinelli</li> </ol>"},{"location":"svm/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<ol> <li>Explora\u00e7\u00e3o de dados: Ao selecionar uma base no kaggle referentes a cinco tipos de rem\u00e9dio, rem\u00e9dio A, B, C, X e Y, tem como objetivo prever qual rem\u00e9dio o paciente teria uma resposta melhor. As colunas presentes nesse dataset s\u00e3o Idade, Sexo, Press\u00e3o Arterial, nivel de colesterol, nivel de s\u00f3dio para pot\u00e1ssio no sangue e rem\u00e9dio que seria nossa target. </li> </ol>"},{"location":"svm/main/#colunas","title":"Colunas","text":"<ol> <li>Age (Idade): Essa coluna temos a idade dos pacientes, com a idade minima presente de 15, idade m\u00e9dia de 44,3 e maxima de 74 sendo do tipo Integer. </li> <li>Sex (Sexo): Essa coluna tem o sexo de cada paciente, divididos em 52% Masculino e 48% feminino, dados do tipo String.</li> <li>Blood Pressure (Press\u00e3o Arterial): Essa coluna tem os niveis de press\u00e3o arterial de cada paciente sendo dividida em 39% HIGH, 29% NORMAL e 32% LOW, dados do tipo String.</li> <li>Cholesterol (nivel de colesterol): Essa coluna tem os niveis de colesterol de cada paciente sendo divididos em 52% HIGH e 49% NORMAL, dados do tipo String.</li> <li>Na_to_K (s\u00f3dio para pot\u00e1ssio): Essa coluna tem os a raz\u00e3o de s\u00f3dio para pot\u00e1ssio no sangue de um paciente, com a minima de 6,27, media de 16,1 e maxima de 38,2, dados do tipo Float/Decimal.</li> <li>Drug (rem\u00e9dio): Essa coluna tem os rem\u00e9dio de melhor resposta para o paciente, dados do tipo String.</li> </ol> Base Age Sex BP Cholesterol Na_to_K Drug 36 M LOW NORMAL 11.424 drugX 16 F HIGH NORMAL 15.516 drugY 18 F NORMAL NORMAL 8.75 drugX 59 F LOW HIGH 10.444 drugC 47 M LOW NORMAL 33.542 drugY 51 M HIGH HIGH 18.295 drugY 18 F HIGH NORMAL 24.276 drugY 28 F NORMAL HIGH 12.879 drugX 42 M HIGH NORMAL 12.766 drugA 66 F NORMAL NORMAL 8.107 drugX"},{"location":"svm/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Primeiro foi feita uma verifica\u00e7\u00e3o em todas as colunas procurando valores faltantes e substituindo eles pela mediana em valores num\u00e9ricos ou pela moda em vari\u00e1veis categ\u00f3ricas. Como vimos na descri\u00e7\u00e3o das colunas temos tr\u00eas que possuem dados categ\u00f3ricos do tipo String, sendo elas Sex(Sexo), Blood Pressure(Press\u00e3o Arterial) e Cholesterol(nivel de colesterol), para conseguirmos utilizar essas informa\u00e7\u00f5es \u00e9 necessario convertelas em numeros, oque foi feito utilizando a biblioteca scikit-learn que possui a fun\u00e7\u00e3o LabelEncoder(), em seguida aplicamos dois tipos de escalonamento \u00e0s colunas num\u00e9ricas Age e Na_to_K: padroniza\u00e7\u00e3o (z-score) e normaliza\u00e7\u00e3o min-max.</p> ResultPrep CodeStandardizationStandardization code N-Age Sex BP Cholesterol N-Na_to_K Drug 0.4 1 1 1 0.130411 drugX 0 0 0 1 0.291292 drugY 0.04 0 2 1 0.0252801 drugX 0.86 0 1 0 0.0918813 drugC 0.62 1 1 1 1 drugY 0.7 1 0 0 0.40055 drugY 0.04 0 0 1 0.635699 drugY 0.24 0 2 0 0.187615 drugX 0.52 1 0 1 0.183173 drugA 1 0 2 1 0 drugX <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Preprocess the data\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\n# Display the first few rows of the dataset\nprint(df.to_markdown(index=False))\n</code></pre> Age N-Age Z-Age Na_to_K N-Na_to_K Z-Na_to_K 95 36 0.4 -0.117416 11.424 0.130411 -0.526121 15 16 0 -1.23566 15.516 0.291292 -0.0105705 30 18 0.04 -1.12384 8.75 0.0252801 -0.863018 158 59 0.86 1.16857 10.444 0.0918813 -0.649591 128 47 0.62 0.49762 33.542 1 2.26052 115 51 0.7 0.72127 18.295 0.40055 0.339555 69 18 0.04 -1.12384 24.276 0.635699 1.0931 170 28 0.24 -0.564715 12.879 0.187615 -0.342806 174 42 0.52 0.218058 12.766 0.183173 -0.357043 45 66 1 1.55996 8.107 0 -0.944029 <pre><code>import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndef standardization(df):\n\n    df['Z-Age'] = df['Age'].apply(lambda x: (x-df['Age'].mean())/df['Age'].std())\n    df['N-Age'] = df['Age'].apply(lambda x: (x-df['Age'].min())/(df['Age'].max()-df['Age'].min()))\n    df['Z-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].mean())/df['Na_to_K'].std())\n    df['N-Na_to_K'] = df['Na_to_K'].apply(lambda x: (x-df['Na_to_K'].min())/(df['Na_to_K'].max()-df['Na_to_K'].min()))\n    df = df[['Age', 'N-Age', 'Z-Age', 'Na_to_K', 'N-Na_to_K', 'Z-Na_to_K']].dropna()\n    print(df.head(10).to_markdown())\n\ndef preprocess(df):\n    # Fill missing values\n    df['Age'].fillna(df['Age'].median(), inplace=True)\n    df['Sex'].fillna(df['Sex'].mode()[0], inplace=True)\n    df['BP'].fillna(df['BP'].mode()[0], inplace=True)\n    df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)\n    df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)\n    df['Drug'].fillna(df['Drug'].mode()[0], inplace=True)\n\n   # Convert categorical variables\n    label_encoder = LabelEncoder()\n    df['Sex'] = label_encoder.fit_transform(df['Sex'])\n    df['BP'] = label_encoder.fit_transform(df['BP'])\n    df['Cholesterol'] = label_encoder.fit_transform(df['Cholesterol'])\n\n    # Select features\n    features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\n    return df[features]\n\n# Load the dataset\ndf = pd.read_csv('data/kaggle/drug200.csv')\ndf = df.sample(n=10, random_state=42)\n\n# Preprocessing\ndf = preprocess(df)\n\nstandardization(df)\n</code></pre>"},{"location":"svm/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O conjunto de dados foi dividido em 70% para treino e 30% para valida\u00e7\u00e3o, garantindo que o modelo fosse treinado em uma parte significativa das observa\u00e7\u00f5es, mas ainda avaliado em dados n\u00e3o vistos. O uso do conjunto de valida\u00e7\u00e3o tem como objetivo detectar e reduzir o risco de overfitting.</p>"},{"location":"svm/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"Result 70% 30%Code Acur\u00e1cia por kernel: kernel accuracy linear 0.950000 sigmoid 0.883333 poly 0.850000 rbf 0.883333 Melhor kernel: linear Accuracy: 0.95 Relat\u00f3rio de Classifica\u00e7\u00e3o: precision recall f1-score support 0 0.777778 1.000000 0.875000 7.00 1 1.000000 0.800000 0.888889 5.00 2 1.000000 1.000000 1.000000 5.00 3 1.000000 0.937500 0.967742 16.00 4 0.962963 0.962963 0.962963 27.00 accuracy 0.950000 0.950000 0.950000 0.95 macro avg 0.948148 0.940093 0.938919 60.00 weighted avg 0.957407 0.950000 0.950889 60.00 Matriz de Confus\u00e3o: 0 1 2 3 4 0 7 0 0 0 0 1 1 4 0 0 0 2 0 0 5 0 0 3 0 0 0 15 1 4 1 0 0 0 26 2025-12-08T17:26:40.734232 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>```python exec=\"0\" html=\"0\" import matplotlib.pyplot as plt from sklearn.inspection import DecisionBoundaryDisplay from sklearn.svm import SVC from io import StringIO import pandas as pd import numpy as np from sklearn.preprocessing import LabelEncoder, StandardScaler from sklearn.decomposition import PCA from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, classification_report, confusion_matrix from sklearn.impute import SimpleImputer</p>"},{"location":"svm/main/#configuracao-para-evitar-warnings-de-atribuicao","title":"Configura\u00e7\u00e3o para evitar warnings de atribui\u00e7\u00e3o","text":"<p>pd.options.mode.chained_assignment = None </p> <p>def preprocess(df):     # Encoding b\u00e1sico de categ\u00f3ricas     le = LabelEncoder()     # Copia para n\u00e3o alterar o original fora da fun\u00e7\u00e3o     df = df.copy()     for col in [\"Sex\", \"BP\", \"Cholesterol\", \"Drug\"]:         if df[col].dtype == 'object':              df[col] = le.fit_transform(df[col].astype(str))     return df</p>"},{"location":"svm/main/#1-carrega-os-dados","title":"1. Carrega os dados","text":"<p>df = pd.read_csv('data/kaggle/drug200.csv')</p>"},{"location":"svm/main/#2-pre-processamento-basico-apenas-conversao-de-strings-para-numeros","title":"2. Pr\u00e9-processamento B\u00e1sico (Apenas convers\u00e3o de strings para n\u00fameros)","text":"<p>df = preprocess(df)</p>"},{"location":"svm/main/#3-define-x-e-y","title":"3. Define X e y","text":""},{"location":"svm/main/#nota-drug-ja-virou-numero-no-preprocess-entao-y-ja-serve-como-y_codes","title":"Nota: Drug j\u00e1 virou n\u00famero no preprocess, ent\u00e3o y j\u00e1 serve como y_codes","text":"<p>features = [\"Age\", \"Sex\", \"BP\", \"Cholesterol\", \"Na_to_K\"] X = df[features].values y = df[\"Drug\"].values</p>"},{"location":"svm/main/#4-traintest-split","title":"4. Train/Test Split","text":""},{"location":"svm/main/#importante-o-split-ocorre-antes-de-imputar-medias-ou-normalizar","title":"Importante: O split ocorre ANTES de imputar m\u00e9dias ou normalizar","text":"<p>X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.3, random_state=42, stratify=y )</p>"},{"location":"svm/main/#5-tratamento-de-nulos-e-escalonamento-pipeline-manual","title":"5. Tratamento de Nulos e Escalonamento (Pipeline Manual)","text":""},{"location":"svm/main/#imputacao-aprende-a-mediana-no-treino-e-aplica-em-treino-e-teste","title":"Imputa\u00e7\u00e3o: Aprende a mediana no TREINO e aplica em TREINO e TESTE","text":"<p>imputer = SimpleImputer(strategy='median') X_train = imputer.fit_transform(X_train) X_test = imputer.transform(X_test)</p>"},{"location":"svm/main/#escalonamento-aprende-a-escala-no-treino-e-aplica-em-treino-e-teste","title":"Escalonamento: Aprende a escala no TREINO e aplica em TREINO e TESTE","text":"<p>scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test)</p>"},{"location":"svm/main/#-correcao-aqui-","title":"--- CORRE\u00c7\u00c3O AQUI ---","text":""},{"location":"svm/main/#para-visualizacao-precisamos-aplicar-as-transformacoes-aprendidas-no-treino","title":"Para visualiza\u00e7\u00e3o, precisamos aplicar as transforma\u00e7\u00f5es aprendidas no treino","text":""},{"location":"svm/main/#em-todo-o-conjunto-de-dados-x-isso-nao-gera-vazamento-pois-os-parametros","title":"em TODO o conjunto de dados (X). Isso n\u00e3o gera vazamento, pois os par\u00e2metros","text":""},{"location":"svm/main/#media-desvio-mediana-vieram-apenas-do-treino","title":"(m\u00e9dia, desvio, mediana) vieram apenas do treino.","text":"<p>X_full_imputed = imputer.transform(X)       # Aplica a mediana do treino em tudo X_scaled_all = scaler.transform(X_full_imputed) # Aplica a escala do treino em tudo</p>"},{"location":"svm/main/#-","title":"---------------------","text":""},{"location":"svm/main/#6-pca","title":"6. PCA","text":"<p>pca = PCA(n_components=2, random_state=42) X_train_pca = pca.fit_transform(X_train_scaled)</p>"},{"location":"svm/main/#projeta-todos-os-dados-no-espaco-2d-criado-pelo-treino","title":"Projeta todos os dados no espa\u00e7o 2D criado pelo treino","text":"<p>X_pca_all = pca.transform(X_scaled_all)</p>"},{"location":"svm/main/#7-figura-e-loop-de-kernels","title":"7. Figura e Loop de Kernels","text":"<p>fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 6))</p> <p>kernels = {     \"linear\": ax1,     \"sigmoid\": ax2,     \"poly\": ax3,     \"rbf\": ax4, }</p> <p>results = []</p>"},{"location":"svm/main/#como-y-ja-e-numerico-devido-ao-labelencoder-usamos-ele-para-colorir","title":"Como y j\u00e1 \u00e9 num\u00e9rico devido ao LabelEncoder, usamos ele para colorir","text":"<p>y_codes = y </p> <p>for k, ax in kernels.items():     # Modelo para m\u00e9tricas (treinado em dados originais escalonados - 5D)     svm_full = SVC(kernel=k, C=1, random_state=42)     svm_full.fit(X_train_scaled, y_train)</p> <pre><code>y_pred = svm_full.predict(X_test_scaled)\nacc = accuracy_score(y_test, y_pred)\nresults.append({\"kernel\": k, \"accuracy\": acc})\n\n# Modelo para visualiza\u00e7\u00e3o (treinado em dados PCA - 2D)\nsvm_vis = SVC(kernel=k, C=1, random_state=42)\nsvm_vis.fit(X_pca_all, y) # Treina com tudo em 2D apenas para desenhar as fronteiras bonitas\n\n# Fronteira de decis\u00e3o\nDecisionBoundaryDisplay.from_estimator(\n    svm_vis,\n    X_pca_all,\n    response_method=\"predict\",\n    alpha=0.8,\n    cmap=\"Pastel1\",\n    ax=ax,\n)\n\n# Plot dos pontos reais\nax.scatter(\n    X_pca_all[:, 0],\n    X_pca_all[:, 1],\n    c=y_codes,\n    s=20,\n    edgecolors=\"k\",\n    cmap=\"viridis\" # Adicionado colormap para garantir cores distintas\n)\n\nax.set_title(k)\nax.set_xticks([])\nax.set_yticks([])\n</code></pre> <p>plt.tight_layout()</p>"},{"location":"svm/main/#8-tabelas-e-metricas","title":"8. Tabelas e M\u00e9tricas","text":"<p>results_df = pd.DataFrame(results)</p> <p>print(\"</p>Acur\u00e1cia por kernel:\") print(results_df.to_html(classes=\"table table-bordered table-striped\", border=0, index=False))<p></p> <p>best_kernel = results_df.loc[results_df[\"accuracy\"].idxmax(), \"kernel\"]</p>"},{"location":"svm/main/#retreinarecupera-melhor-modelo","title":"Retreina/Recupera melhor modelo","text":"<p>best_clf = SVC(kernel=best_kernel, C=1, random_state=42) best_clf.fit(X_train_scaled, y_train) y_pred_best = best_clf.predict(X_test_scaled)</p> <p>print(f\"</p>Melhor kernel: {best_kernel}\") print(f\"Accuracy: {accuracy_score(y_test, y_pred_best)}\")<p></p> <p>report = classification_report(y_test, y_pred_best, output_dict=True) report_df = pd.DataFrame(report).transpose()</p> <p>print(\"</p>Relat\u00f3rio de Classifica\u00e7\u00e3o:\") print(report_df.to_html(classes=\"table table-bordered table-striped\", border=0))<p></p> <p>cm = confusion_matrix(y_test, y_pred_best, labels=best_clf.classes_) cm_df = pd.DataFrame(cm, index=best_clf.classes_, columns=best_clf.classes_)</p> <p>print(\"</p>Matriz de Confus\u00e3o:\") print(cm_df.to_html(classes=\"table table-bordered table-striped\", border=0))<p></p>"},{"location":"svm/main/#9-exporta-imagem","title":"9. Exporta Imagem","text":"<p>buffer = StringIO() plt.savefig(buffer, format=\"svg\", transparent=True) print(buffer.getvalue()) plt.close() ```</p>"},{"location":"svm/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Comparando os diferentes kernels, o linear demonstrou ser a abordagem mais eficaz para este problema, atingindo 95% de acur\u00e1cia e superando os kernels sigmoid (88,3%), rbf (88,3%) e poly (85,0%). A visualiza\u00e7\u00e3o das fronteiras de decis\u00e3o confirma que, ap\u00f3s o pr\u00e9-processamento, os dados se organizam de maneira que hiperplanos lineares s\u00e3o suficientes e eficientes para a separa\u00e7\u00e3o das classes, evitando a complexidade desnecess\u00e1ria de kernels n\u00e3o lineares.</p> <p>A an\u00e1lise detalhada pelo relat\u00f3rio de classifica\u00e7\u00e3o aponta um desempenho robusto: * Performance Ideal: A classe DrugC (2) foi classificada com perfei\u00e7\u00e3o (100% de precis\u00e3o e recall). * Classes Majorit\u00e1rias: As classes DrugX (3) e DrugY (4) apresentaram resultados excelentes, com F1-Scores superiores a 0.96, demonstrando a capacidade do modelo em generalizar bem para os casos mais frequentes. * An\u00e1lise de Erros: A matriz de confus\u00e3o revela que as poucas classifica\u00e7\u00f5es incorretas tiveram um padr\u00e3o espec\u00edfico. A classe DrugA (0) atuou como um \"falso atrator\", absorvendo incorretamente uma inst\u00e2ncia de DrugB e uma de DrugY. Isso resultou em um recall perfeito para DrugA, mas reduziu sua precis\u00e3o para 78%.</p> <p>Em conclus\u00e3o, o SVM linear oferece o melhor equil\u00edbrio entre vi\u00e9s e vari\u00e2ncia para este conjunto de dados, entregando uma solu\u00e7\u00e3o simples, interpret\u00e1vel e com alta taxa de acerto global.</p>"},{"location":"svm/main/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"}]}